This project implements a deep learning–based surveillance system for crime and abnormal activity detection in video sequences. It uses a two-stage architecture: frame-level feature extraction followed by sequence modeling. Each video frame is processed through EfficientNetB0 (pretrained on ImageNet) to obtain high-level visual features. These features are accumulated into fixed-length sequences of 30 frames (or shreded to) and passed to a temporal network for classification.

Multiple sequence models were tested during development, including LSTM, BiLSTM, and GRU. The final deployed model uses a GRU network due to its stable performance and efficient handling of temporal patterns. The model outputs a binary prediction indicating whether the activity in the sequence is normal or potentially criminal.

The prediction pipeline reads a video file, extracts features from each frame, manages the sliding 30-frame window, and performs real-time inference. For every prediction, the system annotates the output frame with a label (“Normal” or “Crime”) and a confidence score. All processed frames are written to an output video file for this demo version. A confidence graph is also generated to visualize prediction trends throughout the video.

The system is modular and can work with any video input. It is suitable for experimentation with temporal models, feature extractors, anomaly detection, and video classification tasks. The project provides a complete workflow, including preprocessing, feature extraction, model inference, and output visualization. The idea to implement this on a real scale would require access to multiple cores at the same time on a powerful GPU to predict with realtime speed and accuracy as given by the webcam code.
